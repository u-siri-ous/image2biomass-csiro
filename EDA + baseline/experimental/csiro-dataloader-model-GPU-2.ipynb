{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fcc7db7a","cell_type":"code","source":"# Imports\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom pathlib import Path\n\n# PyTorch & Lightning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport glob\n\n# Scikit-Learn\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, PowerTransformer\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:11:41.329179Z","iopub.execute_input":"2025-12-10T17:11:41.329807Z","iopub.status.idle":"2025-12-10T17:11:41.334740Z","shell.execute_reply.started":"2025-12-10T17:11:41.329783Z","shell.execute_reply":"2025-12-10T17:11:41.334130Z"}},"outputs":[],"execution_count":31},{"id":"b5adc875","cell_type":"code","source":"class CFG:\n    # Data Paths\n    TRAIN_PATH = \"/kaggle/input/csiro-biomass/train.csv\"         # Update this path\n    TRAIN_DIR = \"/kaggle/input/csiro-biomass/train/\"          # Update this path to where images are stored\n\n    # Test paths\n    TEST_PATH = \"/kaggle/input/csiro-biomass/test.csv\"     # Update this path\n    TEST_DIR = \"/kaggle/input/csiro-biomass/test/\"   # Update this path to where test images are stored\n    \n    # Model Settings\n    # 'vit_base_patch14_dinov2.lvd142m' is good, 'vit_small...' is faster\n    MODEL_NAME = \"vit_base_patch14_dinov2.lvd142m\"\n    IMG_SIZE = 518                 # DINOv2 uses patches of 14 (224/14 = 16)\n    \n    # Hyperparameters\n    BATCH_SIZE = 16                # Lower if OOM\n    EPOCHS = 20\n    EPOCHS_FT = 5    \n    WEIGHT_DECAY = 1e-2\n    N_FOLDS = 5\n    SEED = 42\n    \n    # Differentiated Learning Rates\n    LR_BACKBONE = 1e-6                 # Lower LR for DINOv2 Backbone\n    LR_HEAD = 1e-4                     # Higher LR for Head and Tabular Branch\n    \n    # Features & Targets\n    TARGET_COLS = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g']\n\n    # Feature weights defined by the competition\n    TARGET_WEIGHTS = {\n        'Dry_Total_g': 0.5,\n        'GDM_g': 0.2,\n        'Dry_Green_g': 0.1,\n        'Dry_Dead_g': 0.1,\n        'Dry_Clover_g': 0.1\n    }\n    \n    NUM_FEATS = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n    CAT_FEATS = [\"State\", \"Species\", \"season\"]\n\n    # Number of last blocks of the DINOv2 backbone to unfreeze during fine-tuning\n    NUM_BLOCKS_TO_UNFREEZE = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.466975Z","iopub.execute_input":"2025-12-10T16:23:49.467207Z","iopub.status.idle":"2025-12-10T16:23:49.487520Z","shell.execute_reply.started":"2025-12-10T16:23:49.467182Z","shell.execute_reply":"2025-12-10T16:23:49.486984Z"}},"outputs":[],"execution_count":23},{"id":"aedad0ca","cell_type":"code","source":"def load_and_preprocess_data(train_path):\n    print(\"ðŸ“‚ Loading and formatting data...\")\n    train_df_long = pd.read_csv(train_path)\n    \n    # Extract image ID\n    train_df_long['image_id'] = train_df_long['sample_id'].str.split('__').str[0]\n    \n    # Pivot to Wide Format\n    meta_cols = ['image_path', 'Sampling_Date', 'State', 'Species', \n                 'Pre_GSHH_NDVI', 'Height_Ave_cm']\n    \n    train_df_wide = train_df_long.pivot_table(\n        index=['image_id'] + meta_cols,\n        columns='target_name',\n        values='target',\n        aggfunc='first'\n    ).reset_index()\n   \n    # Temporal Features\n    train_df_wide['date'] = pd.to_datetime(train_df_wide['Sampling_Date'], format='%Y/%m/%d')\n    train_df_wide['month'] = train_df_wide['date'].dt.month\n    \n    # Season (Southern Hemisphere)\n    def get_season(month):\n        if month in [9, 10, 11]: return \"Spring\"\n        elif month in [12, 1, 2]: return \"Summer\"\n        elif month in [3, 4, 5]: return \"Autumn\"\n        else: return \"Winter\"\n        \n    train_df_wide['season'] = train_df_wide['month'].apply(get_season)\n    \n    # Construct full image path\n    # Adjust extension (.png/.jpg) based on your actual data\n    train_df_wide['full_image_path'] = train_df_wide['image_id'].apply(lambda x: os.path.join(CFG.TRAIN_DIR, f\"{x}.png\"))\n    \n    print(f\"âœ… Loaded {len(train_df_wide)} unique train samples.\")\n    return train_df_wide","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.488348Z","iopub.execute_input":"2025-12-10T16:23:49.488553Z","iopub.status.idle":"2025-12-10T16:23:49.512364Z","shell.execute_reply.started":"2025-12-10T16:23:49.488538Z","shell.execute_reply":"2025-12-10T16:23:49.511797Z"}},"outputs":[],"execution_count":24},{"id":"67f6b789","cell_type":"code","source":"class BiomassPreprocessor:\n    \"\"\"\n    Handles scaling of inputs and Log-Transform of targets.\n    Fits ONLY on train data to prevent leakage.\n    \"\"\"\n    def __init__(self):\n        self.pt = PowerTransformer(method=\"yeo-johnson\")\n        self.scaler = RobustScaler()\n        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n        self.cat_cols = CFG.CAT_FEATS\n        self.num_cols = CFG.NUM_FEATS\n        \n    def fit_transform(self, df):\n        # 1. Numeric: Power Transform -> Robust Scale\n        X_num = self.pt.fit_transform(df[self.num_cols])\n        X_num = self.scaler.fit_transform(X_num)\n        \n        # 2. Categorical: One Hot\n        X_cat = self.encoder.fit_transform(df[self.cat_cols])\n        \n        # Combine\n        return np.hstack([X_num, X_cat])\n\n    def transform(self, df):\n        # Use fitted scalers\n        X_num = self.scaler.transform(self.pt.transform(df[self.num_cols]))\n        X_cat = self.encoder.transform(df[self.cat_cols])\n        return np.hstack([X_num, X_cat])\n    \n    def transform_targets(self, df):\n        # Log1p transform to handle skew/outliers in biomass\n        # y = log(x + 1)\n        return np.log1p(df[CFG.TARGET_COLS].values.astype(np.float32))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.513147Z","iopub.execute_input":"2025-12-10T16:23:49.513393Z","iopub.status.idle":"2025-12-10T16:23:49.531188Z","shell.execute_reply.started":"2025-12-10T16:23:49.513373Z","shell.execute_reply":"2025-12-10T16:23:49.530479Z"}},"outputs":[],"execution_count":25},{"id":"ba66a5f9","cell_type":"code","source":"# ==========================================\n# 4. DATASET & TRANSFORMS\n# ==========================================\ntrain_transforms = transforms.Compose([\n    transforms.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nclass BiomassDataset(Dataset):\n    def __init__(self, X_tab, image_paths, y, transform=None):\n        self.X_tab = torch.tensor(X_tab, dtype=torch.float32)\n        self.image_paths = image_paths\n        self.y = torch.tensor(y, dtype=torch.float32)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        # Tabular\n        x_tab = self.X_tab[idx]\n        \n        # Image\n        path = self.image_paths[idx]\n        try:\n            image = Image.open(path).convert(\"RGB\")\n        except Exception as e:\n            # Fallback for missing images\n            image = Image.new('RGB', (CFG.IMG_SIZE, CFG.IMG_SIZE), (0, 0, 0))\n\n        if self.transform:\n            image = self.transform(image)\n            \n        return (x_tab, image), self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.532423Z","iopub.execute_input":"2025-12-10T16:23:49.532632Z","iopub.status.idle":"2025-12-10T16:23:49.551472Z","shell.execute_reply.started":"2025-12-10T16:23:49.532617Z","shell.execute_reply":"2025-12-10T16:23:49.550740Z"}},"outputs":[],"execution_count":26},{"id":"9dd33bdd","cell_type":"code","source":"# ==========================================\n# 5. MODEL ARCHITECTURE\n# ==========================================\nclass BiomassModel(pl.LightningModule):\n    def __init__(self, tabular_input_dim, target_dim=3):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Setup weights for the Loss\n        weights = torch.tensor([CFG.TARGET_WEIGHTS[t] for t in CFG.TARGET_COLS], dtype=torch.float32)\n        # Weights normalized to sum to 1\n        self.target_loss_weights = weights / weights.sum()\n\n        # 1. Vision Backbone (DINOv2)\n        self.dino = timm.create_model(CFG.MODEL_NAME, pretrained=True, num_classes=0, img_size=CFG.IMG_SIZE)\n        \n        # FREEZE Backbone initially to prevent overfitting/catastrophic forgetting\n        for param in self.dino.parameters():\n            param.requires_grad = False\n            \n        dino_out_dim = self.dino.num_features\n\n        # 2. Tabular Branch\n        self.tabular_branch = nn.Sequential(\n            nn.Linear(tabular_input_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n        )\n\n        # 3. Fusion Head\n        self.head = nn.Sequential(\n            nn.Linear(dino_out_dim + 64, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, target_dim)\n        )\n        \n        # Huber Loss is robust to outliers, reduction='none' for custom weighting\n        self.base_criterion = nn.HuberLoss(delta=1.0, reduction='none')\n\n    # Function to calculate weighted loss\n    def calculate_weighted_loss(self, y_pred, y_true):\n        # Calculate base loss per element\n        loss_per_element = self.base_criterion(y_pred, y_true)\n        \n        # Apply target weights (Broadcasting)\n        # The weights tensor has shape [1, 5] and is multiplied by loss [BatchSize, 5]\n        weighted_loss = loss_per_element * self.target_loss_weights.to(self.device)\n        \n        # Return the mean of the weighted loss\n        return weighted_loss.mean()\n\n    def forward(self, x_tab, x_img):\n        # DINO inference (no grad required for backbone)\n        with torch.no_grad():\n            img_feat = self.dino(x_img)\n        \n        tab_feat = self.tabular_branch(x_tab)\n        combined = torch.cat([img_feat, tab_feat], dim=1)\n        return self.head(combined)\n\n    def training_step(self, batch, batch_idx):\n        (x_tab, x_img), y = batch\n        y_pred = self(x_tab, x_img)\n        loss = self.calculate_weighted_loss(y_pred, y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        (x_tab, x_img), y = batch\n        y_pred = self(x_tab, x_img)\n        loss = self.calculate_weighted_loss(y_pred, y)\n        self.log('val_loss', loss, prog_bar=True)\n        return loss\n\n    def configure_optimizers(self):\n        # Filltering backbone parameters that belong to the DINOv2 backbone\n        backbone_params = [p for n, p in self.named_parameters() if 'dino' in n and p.requires_grad]\n        \n        # Head and Tabular Branch parameters\n        head_and_tabular_params = [p for n, p in self.named_parameters() if ('head' in n or 'tabular_branch' in n) and p.requires_grad]\n        \n        # Define two parameter groups with different LRs\n        # higher for head and tabular branch, lower for backbone\n        param_groups = [\n            {'params': head_and_tabular_params, 'lr': CFG.LR_HEAD, 'weight_decay': CFG.WEIGHT_DECAY},\n            {'params': backbone_params, 'lr': CFG.LR_BACKBONE, 'weight_decay': CFG.WEIGHT_DECAY},\n        ]\n        \n        # Define optimizer with parameter groups\n        optimizer = torch.optim.AdamW(param_groups)\n        \n        # Define scheduler\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=3\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.552326Z","iopub.execute_input":"2025-12-10T16:23:49.552957Z","iopub.status.idle":"2025-12-10T16:23:49.573812Z","shell.execute_reply.started":"2025-12-10T16:23:49.552940Z","shell.execute_reply":"2025-12-10T16:23:49.573098Z"}},"outputs":[],"execution_count":27},{"id":"f5e45bd8","cell_type":"code","source":"# ==========================================\n# 6. MAIN TRAINING LOOP (K-FOLD)\n# ==========================================\nif __name__ == \"__main__\":\n    # Load Data\n    train_df_full = load_and_preprocess_data(CFG.TRAIN_PATH)\n    \n    # Setup GroupKFold using Sampling_Date\n    gkf = GroupKFold(n_splits=CFG.N_FOLDS)\n    groups = train_df_full['Sampling_Date'] \n\n    \n    print(f\"\\nðŸš€ Starting training with {CFG.MODEL_NAME}...\")\n\n    # Best model \n    overall_best_loss = float('inf')\n    overall_best_fold_idx = -1\n    overall_best_checkpoint_path = None\n    all_fold_results = []\n    \n    for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df_full, groups=groups)):\n        print(f\"\\n{'='*20} FOLD {fold+1}/{CFG.N_FOLDS} {'='*20}\")\n        \n        # 1. Split Data\n        train_df = train_df_full.iloc[train_idx].reset_index(drop=True)\n        val_df = train_df_full.iloc[val_idx].reset_index(drop=True)\n        \n        # 2. Preprocessing (Fit on Train, Transform Val)\n        processor = BiomassPreprocessor()\n        \n        # Features\n        X_train_tab = processor.fit_transform(train_df)\n        X_val_tab = processor.transform(val_df)\n        \n        # Targets (Log Transformed)\n        y_train = processor.transform_targets(train_df)\n        y_val = processor.transform_targets(val_df)\n        \n        # 3. Create Datasets & Loaders\n        train_ds = BiomassDataset(X_train_tab, train_df['full_image_path'].values, y_train, transform=train_transforms)\n        val_ds = BiomassDataset(X_val_tab, val_df['full_image_path'].values, y_val, transform=val_transforms)\n        \n        train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n        val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)\n        \n        # 4. Initialize Model\n        model = BiomassModel(tabular_input_dim=X_train_tab.shape[1], target_dim=len(CFG.TARGET_COLS))\n        \n        # 5. Setup Trainer\n        checkpoint_callback = ModelCheckpoint(\n            dirpath=f'checkpoints/fold_{fold}',\n            filename='best-{epoch:02d}-{val_loss:.4f}',\n            monitor='val_loss',\n            mode='min',\n            save_top_k=1\n        )\n        \n        early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n        \n        trainer = pl.Trainer(\n            max_epochs=CFG.EPOCHS,\n            accelerator=\"auto\",\n            devices=1,\n            precision=\"16-mixed\",  # Uses FP16 to save memory & speed up\n            callbacks=[checkpoint_callback, early_stop],\n            logger=False,          # Set to True if using WandB/Tensorboard\n            enable_progress_bar=True\n        )\n        \n        # 6. Train\n        trainer.fit(model, train_loader, val_loader)\n\n\n        print(\"\\n Unfreezing Backbone for Fine-Tuning...\")\n\n        # Unfreeze last N blocks of DINOv2 Backbone\n        # Start from the end of the blocks list\n        for i in range(1, CFG.NUM_BLOCKS_TO_UNFREEZE + 1):\n             for param in model.dino.blocks[-i].parameters():\n                 param.requires_grad = True\n\n        # Unfreeze Batch Norm layers which are often problematic if frozen\n        for param in model.dino.norm.parameters():\n            param.requires_grad = True\n        \n        print(f\"Unfroze the last {CFG.NUM_BLOCKS_TO_UNFREEZE} blocks of the Backbone.\")\n        \n        # New set of callbacks for Fine-Tuning with shorter EarlyStopping\n        checkpoint_callback_ft = ModelCheckpoint(\n            dirpath=f'checkpoints/fold_{fold}/finetune',\n            filename='best-ft-{epoch:02d}-{val_loss:.4f}',\n            monitor='val_loss',\n            mode='min',\n            save_top_k=1\n        )\n        early_stop_ft = EarlyStopping(monitor='val_loss', patience=3, mode='min') \n        \n        # Fine Tuning Phase with a newer Trainer with reduced epochs\n        trainer_ft = pl.Trainer(\n            max_epochs=CFG.EPOCHS_FT,\n            devices=1,\n            precision=\"16-mixed\",\n            callbacks=[checkpoint_callback_ft, early_stop_ft],\n            logger=False, \n            enable_progress_bar=True\n        )\n        \n        # Train Fine-Tuning\n        trainer_ft.fit(model, train_loader, val_loader)\n        \n        # Select the best score between Warm-up and Fine-Tuning\n        best_warmup_loss = checkpoint_callback.best_model_score.item() if checkpoint_callback.best_model_score is not None else float('inf')\n        best_finetune_loss = checkpoint_callback_ft.best_model_score.item() if checkpoint_callback_ft.best_model_score is not None else float('inf')\n\n        if best_warmup_loss <= best_finetune_loss:\n            best_loss_current_fold = best_warmup_loss\n            best_path_current_fold = checkpoint_callback.best_model_path\n        else:\n            best_loss_current_fold = best_finetune_loss\n            best_path_current_fold = checkpoint_callback_ft.best_model_path\n\n\n        print(f\"Fold {fold+1} Complete.\")\n        print(f\"Best Warm-up Loss: {best_warmup_loss:.4f}\")\n        print(f\"Best Fine-Tuning Loss: {best_finetune_loss:.4f}\")\n        print(f\"Best Global Loss for Fold {fold+1}: {best_loss_current_fold:.4f}\")\n\n        # Update the best global model\n        if best_loss_current_fold < overall_best_loss:\n            overall_best_loss = best_loss_current_fold\n            overall_best_fold_idx = fold\n            overall_best_checkpoint_path = best_path_current_fold\n\n        # Memorize results for R2\n        all_fold_results.append({\n            'fold': fold,\n            'best_loss': best_loss_current_fold,\n            'path': best_path_current_fold,\n            'train_idx': train_idx,\n            'val_idx': val_idx\n        })\n\n\n    print(\"\\nðŸŽ‰ GroupKFold Cross-Validation Completed Successfully!\")\n    print(f\"\\nâ­ Overall Best Model is from FOLD {overall_best_fold_idx+1} with Loss: {overall_best_loss:.4f}\")\n    print(f\"Best Checkpoint Path: {overall_best_checkpoint_path}\")\n\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:23:49.574548Z","iopub.execute_input":"2025-12-10T16:23:49.574795Z","iopub.status.idle":"2025-12-10T17:00:39.347078Z","shell.execute_reply.started":"2025-12-10T16:23:49.574750Z","shell.execute_reply":"2025-12-10T17:00:39.346078Z"}},"outputs":[{"name":"stdout","text":"ðŸ“‚ Loading and formatting data...\nâœ… Loaded 357 unique train samples.\n\nðŸš€ Starting training with vit_base_patch14_dinov2.lvd142m...\n\n==================== FOLD 1/5 ====================\n","output_type":"stream"},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_0 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.6 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n226 K     Trainable params\n86.6 M    Non-trainable params\n86.8 M    Total params\n347.225   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b32ac32ecb041b3abee33e91a8f60a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_0/finetune exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.6 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n14.4 M    Trainable params\n72.4 M    Non-trainable params\n86.8 M    Total params\n347.225   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"name":"stdout","text":"\n Unfreezing Backbone for Fine-Tuning...\nUnfroze the last 2 blocks of the Backbone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5d2caeef89459ca13f141e8c68dfc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 Complete.\nBest Warm-up Loss: 0.0711\nBest Fine-Tuning Loss: 0.1913\nBest Global Loss for Fold 1: 0.0711\n\n==================== FOLD 2/5 ====================\n","output_type":"stream"},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_1 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.7 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n226 K     Trainable params\n86.6 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407a1375a2d24fb2bfcd79d9007343a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=20` reached.\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_1/finetune exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.7 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n14.4 M    Trainable params\n72.4 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"name":"stdout","text":"\n Unfreezing Backbone for Fine-Tuning...\nUnfroze the last 2 blocks of the Backbone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b3677aac5a4243b02229949a759f62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Fold 2 Complete.\nBest Warm-up Loss: 0.0436\nBest Fine-Tuning Loss: 0.3427\nBest Global Loss for Fold 2: 0.0436\n\n==================== FOLD 3/5 ====================\n","output_type":"stream"},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_2 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.7 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n226 K     Trainable params\n86.6 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc3308c2f41e41ea93328819e54aa6cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=20` reached.\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_2/finetune exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.7 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n14.4 M    Trainable params\n72.4 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"name":"stdout","text":"\n Unfreezing Backbone for Fine-Tuning...\nUnfroze the last 2 blocks of the Backbone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e18f01f36114b0f9d49677f77122404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"},{"name":"stdout","text":"Fold 3 Complete.\nBest Warm-up Loss: 0.0581\nBest Fine-Tuning Loss: 0.2154\nBest Global Loss for Fold 3: 0.0581\n\n==================== FOLD 4/5 ====================\n","output_type":"stream"},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_3 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.8 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n226 K     Trainable params\n86.6 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907f7a54e20b49da87a187beafb501ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_3/finetune exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 11.8 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n14.4 M    Trainable params\n72.4 M    Non-trainable params\n86.8 M    Total params\n347.226   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"name":"stdout","text":"\n Unfreezing Backbone for Fine-Tuning...\nUnfroze the last 2 blocks of the Backbone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e73a3a10c24494f86beefbe4296cb3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"},{"name":"stdout","text":"Fold 4 Complete.\nBest Warm-up Loss: 0.0623\nBest Fine-Tuning Loss: 0.2085\nBest Global Loss for Fold 4: 0.0623\n\n==================== FOLD 5/5 ====================\n","output_type":"stream"},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_4 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 12.0 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n227 K     Trainable params\n86.6 M    Non-trainable params\n86.8 M    Total params\n347.227   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ea7567b3ffb4286be3ae2a6a0980d46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /kaggle/working/checkpoints/fold_4/finetune exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name           | Type              | Params | Mode \n-------------------------------------------------------------\n0 | dino           | VisionTransformer | 86.6 M | train\n1 | tabular_branch | Sequential        | 12.0 K | train\n2 | head           | Sequential        | 215 K  | train\n3 | base_criterion | HuberLoss         | 0      | train\n-------------------------------------------------------------\n14.4 M    Trainable params\n72.4 M    Non-trainable params\n86.8 M    Total params\n347.227   Total estimated model params size (MB)\n291       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"name":"stdout","text":"\n Unfreezing Backbone for Fine-Tuning...\nUnfroze the last 2 blocks of the Backbone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d847cb9f3ce4e06ad2f2f753a6ee8cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"},{"name":"stdout","text":"Fold 5 Complete.\nBest Warm-up Loss: 0.0634\nBest Fine-Tuning Loss: 0.1160\nBest Global Loss for Fold 5: 0.0634\n\nðŸŽ‰ GroupKFold Cross-Validation Completed Successfully!\n\nâ­ Overall Best Model is from FOLD 2 with Loss: 0.0436\nBest Checkpoint Path: /kaggle/working/checkpoints/fold_1/best-epoch=18-val_loss=0.0436.ckpt\n\nðŸ“ Calculating R-squared (R2) score on the validation set of the best fold...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/621812737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# 5. Calculate the R-squared (R2) Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# multioutput='variance_weighted' is appropriate for multi-target metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'variance_weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nðŸŽ‰ Final Result: R-squared (R2) score for the Best Model: {r2:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"],"ename":"NameError","evalue":"name 'r2_score' is not defined","output_type":"error"}],"execution_count":28},{"id":"49e4440c-00a8-455d-b7a2-d247054cea0e","cell_type":"code","source":" # Compute R2 score\nif overall_best_checkpoint_path and overall_best_fold_idx != -1:\n    # Select data and indices of the best fold\n    best_result = [r for r in all_fold_results if r['fold'] == overall_best_fold_idx][0]\n    train_idx = best_result['train_idx']\n    val_idx = best_result['val_idx']\n\n    print(\"\\nðŸ“ Calculating R-squared (R2) score on the validation set of the best fold...\")\n\n    # 1. Restore the datasets\n    train_df = train_df_full.iloc[train_idx].reset_index(drop=True)\n    val_df = train_df_full.iloc[val_idx].reset_index(drop=True)\n\n    # 2. Preprocessing (Fit on Train, Transform on Val)\n    processor = BiomassPreprocessor()\n    X_train_tab = processor.fit_transform(train_df) # Fit on train\n    X_val_tab = processor.transform(val_df)         # Transform on val\n    y_val = processor.transform_targets(val_df)     # Real validation targets (Log Transformed)\n    # 3. Create the Validation DataLoader (new, drop_last=False, as done above)\n    val_ds = BiomassDataset(X_val_tab, val_df['full_image_path'].values, y_val, transform=val_transforms)\n    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n\n    # 4. Load the Model and Predict\n    tabular_input_dim = X_train_tab.shape[1]\n    target_dim = len(CFG.TARGET_COLS)\n\n    # Load the model from the checkpoint\n    model = BiomassModel.load_from_checkpoint(\n        overall_best_checkpoint_path,\n        tabular_input_dim=tabular_input_dim,\n        target_dim=target_dim,\n        strict=False\n    )\n\n    # Prepare for inference\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for (x_tab, x_img), y in val_loader:\n            x_tab = x_tab.to(device)\n            x_img = x_img.to(device)\n            y_pred = model(x_tab, x_img)\n\n            all_preds.append(y_pred.cpu().numpy())\n            all_targets.append(y.cpu().numpy())\n\n    y_pred_np = np.concatenate(all_preds)\n    y_true_np = np.concatenate(all_targets)\n\n    # 5. Calculate the R-squared (R2) Score\n    # multioutput='variance_weighted' is appropriate for multi-target metrics\n    r2 = r2_score(y_true_np, y_pred_np, multioutput='variance_weighted')\n\n    print(f\"\\nðŸŽ‰ Final Result: R-squared (R2) score for the Best Model: {r2:.4f}\")\nelse:\n    print(\"\\nâš ï¸ Unable to perform R2 evaluation: No model checkpoint was saved or found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:11:48.916280Z","iopub.execute_input":"2025-12-10T17:11:48.917034Z","iopub.status.idle":"2025-12-10T17:11:55.613192Z","shell.execute_reply.started":"2025-12-10T17:11:48.917004Z","shell.execute_reply":"2025-12-10T17:11:55.612334Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“ Calculating R-squared (R2) score on the validation set of the best fold...\n\nðŸŽ‰ Final Result: R-squared (R2) score for the Best Model: 0.3096\n","output_type":"stream"}],"execution_count":32}]}