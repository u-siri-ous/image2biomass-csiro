{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0673a4",
   "metadata": {},
   "source": [
    "# ðŸŒ¾ CSIRO Image2Biomass: Data Augmentation and Training Notebook\n",
    "\n",
    "**Competition:** [CSIRO Image2Biomass Prediction](https://www.kaggle.com/competitions/csiro-biomass)\n",
    "\n",
    "**Thank you CigarCat for the useful EDA** [NB link](https://www.kaggle.com/code/takahitomizunobyts/csiro-customizable-eda)\n",
    "\n",
    "**Thank you Zhuang Jia for some of the albumentations** [NB link](https://www.kaggle.com/code/jiazhuang/csiro-simple)\n",
    "\n",
    "**Thank you Sagar Nagpure for the DINO baseline model**[NB link](https://www.kaggle.com/code/sagarnagpure1310/csiro-dinov2-tiled-lb-0-65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch & Lightning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, PowerTransformer\n",
    "import timm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # Data Paths\n",
    "    # CSV_PATH_TRAIN = \"csiro-biomass\\\\train.csv\"\n",
    "    # IMAGE_DIR_TRAIN = \"csiro-biomass\\\\train\"\n",
    "\n",
    "    # CSV_PATH_TEST = \"csiro-biomass\\\\test.csv\"\n",
    "    # IMAGE_DIR_TEST = \"csiro-biomass\\\\test\"      # This contains a singular image! The rest of them are semiprivate\n",
    "\n",
    "    # Kaggle Data Paths (toggle on Kaggle)\n",
    "    CSV_PATH_TRAIN = \"/kaggle/input/csiro-biomass/train.csv\"\n",
    "    IMAGE_DIR_TRAIN = \"/kaggle/input/csiro-biomass/train\"\n",
    "\n",
    "    CSV_PATH_TEST = \"/kaggle/input/csiro-biomass/test.csv\"\n",
    "    IMAGE_DIR_TEST = \"/kaggle/input/csiro-biomass/test\"\n",
    "    \n",
    "    # Model Settings\n",
    "    # 'vit_base_patch14_dinov2.lvd142m' is good, 'vit_small...' is faster\n",
    "    MODEL_NAME = \"vit_base_patch14_dinov2.lvd142m\"\n",
    "    IMG_SIZE = 518                 # DINOv2 uses patches of 14 (224/14 = 16)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    BATCH_SIZE = 16                # Lower if OOM\n",
    "    EPOCHS = 20\n",
    "    LR = 1e-4\n",
    "    WEIGHT_DECAY = 1e-2\n",
    "    N_FOLDS = 5\n",
    "    SEED = 42\n",
    "    \n",
    "    # Features & Targets\n",
    "    TARGET_COLS = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g']\n",
    "    \n",
    "    NUM_FEATS = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n",
    "    CAT_FEATS = [\"State\", \"Species\", \"season\"]\n",
    "\n",
    "    # Weights (specified in competition overview)\n",
    "    TARGET_WEIGHTS = {\"Dry_Green_g\": 0.1, \"Dry_Dead_g\": 0.1, \"Dry_Clover_g\": 0.1, \"GDM_g\": 0.2 , \"Dry_Total_g\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedad0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(csv_path):\n",
    "    print(\"Loading and formatting data...\")\n",
    "    df_long = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract image ID\n",
    "    df_long['image_id'] = df_long['sample_id'].str.split('__').str[0]\n",
    "    \n",
    "    # Pivot to Wide Format\n",
    "    meta_cols = ['image_path', 'Sampling_Date', 'State', 'Species', \n",
    "                 'Pre_GSHH_NDVI', 'Height_Ave_cm']\n",
    "    \n",
    "    df_wide = df_long.pivot_table(\n",
    "        index=['image_id'] + meta_cols,\n",
    "        columns='target_name',\n",
    "        values='target',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Temporal Features\n",
    "    df_wide['date'] = pd.to_datetime(df_wide['Sampling_Date'], format='%Y/%m/%d')\n",
    "    df_wide['month'] = df_wide['date'].dt.month\n",
    "    \n",
    "    # Season (Southern Hemisphere)\n",
    "    def get_season(month):\n",
    "        if month in [9, 10, 11]: return \"Spring\"\n",
    "        elif month in [12, 1, 2]: return \"Summer\"\n",
    "        elif month in [3, 4, 5]: return \"Autumn\"\n",
    "        else: return \"Winter\"\n",
    "        \n",
    "    df_wide['season'] = df_wide['month'].apply(get_season)\n",
    "    \n",
    "    # Construct full image path\n",
    "    # Adjust extension (.png/.jpg) based on your actual data\n",
    "    df_wide['full_image_path'] = df_wide['image_id'].apply(lambda x: os.path.join(CFG.IMAGE_DIR_TRAIN, f\"{x}.png\"))\n",
    "    \n",
    "    print(f\"Loaded {len(df_wide)} unique samples.\")\n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassPreprocessor:\n",
    "    \"\"\"\n",
    "    Handles scaling of inputs and Log-Transform of targets.\n",
    "    Fits ONLY on train data to prevent leakage.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "        self.scaler = RobustScaler()\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        self.cat_cols = CFG.CAT_FEATS\n",
    "        self.num_cols = CFG.NUM_FEATS\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        # 1. Numeric: Power Transform -> Robust Scale\n",
    "        X_num = self.pt.fit_transform(df[self.num_cols])\n",
    "        X_num = self.scaler.fit_transform(X_num)\n",
    "\n",
    "        # 2. Categorical: One Hot\n",
    "        X_cat = self.encoder.fit_transform(df[self.cat_cols])\n",
    "\n",
    "        # Combine\n",
    "        return np.hstack([X_num, X_cat])\n",
    "\n",
    "    def transform(self, df):\n",
    "        # Use fitted scalers\n",
    "        X_num = self.scaler.transform(self.pt.transform(df[self.num_cols]))\n",
    "        X_cat = self.encoder.transform(df[self.cat_cols])\n",
    "        return np.hstack([X_num, X_cat])\n",
    "\n",
    "    def transform_targets(self, df):\n",
    "        # Log1p transform to handle skew/outliers in biomass\n",
    "        return np.log1p(df[CFG.TARGET_COLS].values.astype(np.float32))\n",
    "\n",
    "    def inverse_transform_targets(self, y_pred):\n",
    "        # Inverse of log1p is expm1\n",
    "        return np.expm1(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. DATASET & TRANSFORMS\n",
    "# ==========================================\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(\n",
    "        CFG.IMG_SIZE,              # output size\n",
    "        scale=(0.8, 1.0),          # random area of the image to crop\n",
    "        ratio=(0.75, 1.33)         # aspect ratio range\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, X_tab, image_paths, y, transform=None):\n",
    "        self.X_tab = torch.tensor(X_tab, dtype=torch.float32)\n",
    "        self.image_paths = image_paths\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tabular\n",
    "        x_tab = self.X_tab[idx]\n",
    "        \n",
    "        # Image\n",
    "        path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # Fallback for missing images\n",
    "            image = Image.new('RGB', (CFG.IMG_SIZE, CFG.IMG_SIZE), (0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (x_tab, image), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd33bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "class BiomassModel(pl.LightningModule):\n",
    "    def __init__(self, tabular_input_dim, target_dim=3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 1. Vision Backbone (DINOv2)\n",
    "        self.dino = timm.create_model(CFG.MODEL_NAME, pretrained=True, num_classes=0, img_size=CFG.IMG_SIZE)\n",
    "        \n",
    "        # FREEZE Backbone initially to prevent overfitting/catastrophic forgetting\n",
    "        for param in self.dino.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        dino_out_dim = self.dino.num_features\n",
    "\n",
    "        # 2. Tabular Branch\n",
    "        self.tabular_branch = nn.Sequential(\n",
    "            nn.Linear(tabular_input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 3. Fusion Head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(dino_out_dim + 64, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, target_dim)\n",
    "        )\n",
    "        \n",
    "        # Huber Loss is robust to outliers\n",
    "        self.criterion = nn.HuberLoss(delta=1.0)\n",
    "\n",
    "    def forward(self, x_tab, x_img):\n",
    "        # DINO inference (no grad required for backbone)\n",
    "        img_feat = self.dino(x_img)\n",
    "        \n",
    "        tab_feat = self.tabular_branch(x_tab)\n",
    "        combined = torch.cat([img_feat, tab_feat], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x_tab, x_img), y = batch\n",
    "        y_pred = self(x_tab, x_img)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (x_tab, x_img), y = batch\n",
    "        y_pred = self(x_tab, x_img)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=CFG.LR, weight_decay=CFG.WEIGHT_DECAY)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=3\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507afdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================= \n",
    "# # 5.1 COMPUTING WEIGHTED R2 CALLBACK \n",
    "# #========================================= \n",
    "class WeightedR2Callback(pl.Callback): \n",
    "    def __init__(self, val_loader, processor, target_names): \n",
    "        super().__init__() \n",
    "        self.val_loader = val_loader \n",
    "        self.processor = processor \n",
    "        self.target_names = target_names \n",
    "\n",
    "    def compute_weighted_r2(self, y_true, y_pred, target_names): \n",
    "        r2s = [] \n",
    "        weights = [] \n",
    "        for i, name in enumerate(target_names): \n",
    "            r2 = r2_score(y_true[:, i], y_pred[:, i]) \n",
    "            r2s.append(r2) \n",
    "            weights.append(CFG.TARGET_WEIGHTS.get(name, 0)) \n",
    "        r2s = np.array(r2s) \n",
    "        weights = np.array(weights) \n",
    "        return np.average(r2s, weights=weights) \n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module): \n",
    "        pl_module.eval() \n",
    "        preds, targets = [], [] \n",
    "        with torch.no_grad(): \n",
    "            for (x_tab, x_img), y in self.val_loader: \n",
    "                x_tab = x_tab.to(pl_module.device) \n",
    "                x_img = x_img.to(pl_module.device) \n",
    "                y = y.to(pl_module.device) \n",
    "                y_pred = pl_module(x_tab, x_img) \n",
    "                preds.append(y_pred.cpu().numpy()) \n",
    "                targets.append(y.cpu().numpy()) \n",
    "        y_pred = np.concatenate(preds, axis=0) \n",
    "        y_true = np.concatenate(targets, axis=0) \n",
    "        y_pred_orig = self.processor.inverse_transform_targets(y_pred) \n",
    "        y_true_orig = self.processor.inverse_transform_targets(y_true) \n",
    "        w_r2 = self.compute_weighted_r2(y_true_orig, y_pred_orig, self.target_names) \n",
    "        trainer.log_metrics({\"w_r2\": w_r2}, step=trainer.global_step) \n",
    "        trainer.callback_metrics[\"w_r2\"] = torch.tensor(w_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e45bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. MAIN TRAINING LOOP (K-FOLD)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Data\n",
    "    df = load_and_preprocess_data(CFG.CSV_PATH_TRAIN)\n",
    "\n",
    "    # Setup K-Fold\n",
    "    kfold = KFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "\n",
    "    print(f\"\\nStarting training with {CFG.MODEL_NAME}...\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df)):\n",
    "        print(f\"\\n{'='*20} FOLD {fold+1}/{CFG.N_FOLDS} {'='*20}\")\n",
    "\n",
    "        # 1. Split Data\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # 2. Preprocessing (Fit on Train, Transform Val)\n",
    "        processor = BiomassPreprocessor()\n",
    "        X_train_tab = processor.fit_transform(train_df)\n",
    "        X_val_tab = processor.transform(val_df)\n",
    "        y_train = processor.transform_targets(train_df)\n",
    "        y_val = processor.transform_targets(val_df)\n",
    "\n",
    "        # 3. Create Datasets & Loaders\n",
    "        train_ds = BiomassDataset(X_train_tab, train_df['full_image_path'].values, y_train, transform=train_transforms)\n",
    "        val_ds = BiomassDataset(X_val_tab, val_df['full_image_path'].values, y_val, transform=val_transforms)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # 4. Initialize Model\n",
    "        model = BiomassModel(tabular_input_dim=X_train_tab.shape[1], target_dim=len(CFG.TARGET_COLS))\n",
    "\n",
    "        # 5. Setup Trainer\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/fold_{fold}',\n",
    "            filename='best-{epoch:02d}-{w_r2:.4f}',\n",
    "            monitor='w_r2',   # monitor weighted RÂ²\n",
    "            mode='max',\n",
    "            save_top_k=1\n",
    "        )\n",
    "        early_stop = EarlyStopping(monitor='w_r2', patience=5, mode='max')\n",
    "\n",
    "        weighted_r2_cb = WeightedR2Callback(val_loader, processor, CFG.TARGET_COLS)\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=CFG.EPOCHS,\n",
    "            accelerator=\"auto\",\n",
    "            devices=1,\n",
    "            precision=\"16-mixed\",\n",
    "            callbacks=[checkpoint_callback, early_stop, weighted_r2_cb],\n",
    "            logger=False,\n",
    "            enable_progress_bar=True\n",
    "        )\n",
    "\n",
    "        # 6. Train\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        # 7. Compute Weighted R^2 Score on Validation Set\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x_tab, x_img), y in val_loader:\n",
    "                y_pred = model(x_tab.to(model.device), x_img.to(model.device))\n",
    "                val_preds.append(y_pred.cpu().numpy())\n",
    "                val_targets.append(y.cpu().numpy())\n",
    "\n",
    "        val_preds = np.concatenate(val_preds, axis=0)\n",
    "        val_targets = np.concatenate(val_targets, axis=0)\n",
    "\n",
    "        # Inverse transform back to original biomass units\n",
    "        val_preds_orig = processor.inverse_transform_targets(val_preds)\n",
    "        val_targets_orig = processor.inverse_transform_targets(val_targets)\n",
    "\n",
    "        # Weighted RÂ²\n",
    "        w_r2 = WeightedR2Callback.compute_weighted_r2(val_targets_orig, val_preds_orig, CFG.TARGET_COLS)\n",
    "        print(f\"Fold {fold+1} Complete. Best Weighted RÂ²: {w_r2:.4f}\")\n",
    "\n",
    "    print(\"\\nCross-Validation Completed Successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
